# Appendix B. Generating Haar Cascades for Custom Targets

This appendix shows how to generate Haar cascade XML files like the ones used in [Chapter 4](4.html#filepos199799 "Chapter 4. Tracking Faces with Haar Cascades"), *Tracking Faces with Haar Cascades*. By generating our own cascade files, we can potentially track any pattern or object, not just faces. However, good results might not come quickly. We must carefully gather images, configure script parameters, perform real-world tests, and iterate. A lot of human time and processing time might be involved.

# Gathering positive and negative training images

Do you know the flashcard pedagogy? It is a method of teaching words and recognition skills to small children. The teacher shows the class a series of pictures and says the following:

> "This is a cow. Moo! This is a horse. Neigh!"

The way that cascade files are generated is analogous to the flashcard pedagogy. To learn how to recognize cows, the computer needs **positive training images** that are pre-identified as cows and **negative training images** that are pre-identified as *non-cows*. Our first step, as trainers, is to gather these two sets of images.

When deciding how many positive training images to use, we need to consider the various ways in which our users might view the target. The ideal, simplest case is that the target is a 2D pattern that is always on a flat surface. In this case, one positive training image might be enough. However, in other cases, hundreds or even thousands of training images might be required. Suppose that the target is your country's flag. When printed on a document, the flag might have a predictable appearance but when printed on a piece of fabric that is blowing in the wind, the flag's appearance is highly variable. A natural, 3D target, such as a human face, might range even more widely in appearance. Ideally, our set of positive training images should be representative of the many variations our camera may capture. Optionally, any of our positive training images may contain multiple instances of the target.

For our negative training set, we want a large number of images that do not contain any instances of the target but do contain other things that our camera is likely to capture. For example, if a flag is our target, our negative training set might include photos of the sky in various weather conditions. (The sky is not a flag but is often seen behind a flag.) Do not assume too much though. If the camera's environment is unpredictable and the target occurs in many settings, use a wide variety of negative training images. Consider building a set of generic environmental images that you can reuse across multiple training scenarios.

# Finding the training executables

To automate cascade training as much as possible, OpenCV provides two executables. Their names and locations depend on the operating system and the particular setup of OpenCV, as described in the following two sections.

## On Windows

The two executables on Windows are called `ONopencv_createsamples.exe` and `ONopencv_traincascade.exe`. They are not prebuilt. Rather, they are present only if you compiled OpenCV from source. Their parent folder is one of the following, depending on the compilation approach you chose in [Chapter 1](1.html#filepos39383 "Chapter 1. Setting up OpenCV"), *Setting up OpenCV*:

*   MinGW：`<unzip_destination>\bin`
*   Visual Studio 或 Visual C ++ Express：`<unzip_destination>\bin\Release`

If you want to add the executables' folder to the system's `Path` variable, refer back to the instructions in the information box in the *Making the choice on Windows XP, Windows Vista, Windows 7, and Windows 8* section of [Chapter 1](1.html#filepos39383 "Chapter 1. Setting up OpenCV"), *Setting up OpenCV*. Otherwise, take note of the executables' full path because we will need to use it in running them.

## On Mac, Ubuntu, and other Unix-like systems

The two executables on Mac, Ubuntu, and other Unix-like systems are called `opencv_createsamples` and `opencv_traincascade`. Their parent folder is one of the following, depending on your system and the approach that you chose in [Chapter 1](1.html#filepos39383 "Chapter 1. Setting up OpenCV"), *Setting up OpenCV*:

*   带有 MacPorts 的 Mac：`/opt/local/bin`
*   带有 Homebrew 的 Mac：`/opt/local/bin`或`/opt/local/sbin`
*   具有 Apt 的 Ubuntu：`/usr/bin`
*   使用我的自定义安装脚本的 Ubuntu：`/usr/local/bin`
*   其他类 Unix 系统：`/usr/bin`和`/usr/local/bin`

Except in the case of Mac with Homebrew, the executables' folder should be in `PATH` by default. For Homebrew, if you want to add the relevant folders to `PATH`, see the instructions in the second step of the *Using Homebrew with ready-made packages (no support for depth cameras)* section of [Chapter 1](1.html#filepos39383 "Chapter 1. Setting up OpenCV"), *Setting up OpenCV*. Otherwise, note the executables' full path because we will need to use it in running them.

# Creating the training sets and cascade

Hereafter, we will refer to the two executables as `<opencv_createsamples>` and `<opencv_traincascade>`. Remember to substitute the path and filename that are appropriate to your system and setup.

These executables have certain data files as inputs and outputs. Following is a typical approach to generating these data files:

1.  手动创建一个描述负面训练图像集的文本文件。 我们将此文件称为`<negative_description>`。
2.  手动创建一个描述正面训练图像集的文本文件。 我们将此文件称为`<positive_description>`。
3.  以`<negative_description>`和`<positive_description>`作为参数运行`<opencv_createsamples>`。 该可执行文件将创建一个描述训练数据的二进制文件。 我们将后一个文件称为`<binary_description>`。
4.  以`<binary_description>`作为参数运行`<opencv_traincascade>`。 该可执行文件创建二进制级联文件，我们将其称为`<cascade>`。

The actual names and paths of `<negative_description>`, `<positive_description>`, `<binary_description>`, and `<cascade>` may be anything we choose.

Now, let's look at each of the three steps in detail.

## Creating <negative_description>

`<negative_description>` is a text file listing the relative paths to all negative training images. The paths should be separated by line breaks. For example, suppose we have the following directory structure, where `<negative_description>` is `negative/desc.txt`:

```py
negative
    desc.txt
    images
        negative 0.png
        negative 1.png
```

Then, the contents of `negative/desc.txt` could be as follows:

```py
"images/negative 0.png"
"images/negative 1.png"
```

For a small number of images, we can write such a file by hand. For a large number of images, we should instead use the command line to find relative paths matching a certain pattern and to output these matches to a file. Continuing our example, we could generate `negative/desc.txt` by running the following commands on Windows in Command Prompt:

```py

> cd negative
> forfiles /m images\*.png /c "cmd /c echo @relpath" > desc.txt

```

Note that in this case, relative paths are formatted as `.\images\negative 0.png`, which is acceptable.

Alternatively, in a Unix-like shell, such as Terminal on Mac or Ubuntu, we could run the following commands:

```py

$ cd negative
$ find images/*.png | sed -e "s/^/\"/g;s/$/\"/g" > desc.txt

```

## Creating <positive_description>

`<positive_description>` is needed if we have more than one positive training image. Otherwise, proceed to the next section. `<positive_description>` is a text file listing the relative paths to all positive training images. After each path, `<positive_description>` also contains a series of numbers indicating how many instances of the target are found in the image and which sub-rectangles contain those instances of the target. For each sub-rectangle, the numbers are in this order: x, y, width, and height. Consider the following example:

```py
"images/positive 0.png"  1  120 160 40 40
"images/positive 1.png"  2  200 120 40 60  80 60 20 20
```

Here, `images/positive 0.png` contains one instance of the target in a sub-rectangle whose upper-left corner is at (120, 160) and whose lower-right corner is at (160, 200). Meanwhile, `images/positive 1.png` contains two instances of the target. One instance is in a sub-rectangle whose upper-left corner is at (200, 120) and whose lower-right corner is at (240, 180). The other instance is in a sub-rectangle whose upper-left corner is at (80, 60) and whose lower-right corner is at (100, 80).

To create such a file, we can start by generating the list of image paths in the same manner as for `<negative_description>`. Then, we must manually add data about target instances based on an expert (human) analysis of the images.

## Creating <binary_description> by running <opencv_createsamples>

Assuming we have multiple positive training images and, thus, we created `<positive_description>`, we can now generate `<binary_description>` by running the following command:

```py

$ <opencv_createsamples> -vec <binary_description> -info <positive_description> -bg <negative_description>

```

Alternatively, if we have a single positive training image, which we will refer to as `<positive_image>`, we should run the following command instead:

```py

$ <opencv_createsamples> -vec <binary_description> -image <positive_image> -bg <negative_description>

```

For other (optional) flags of `<opencv_createsamples>`, see the official documentation at [http://docs.opencv.org/doc/user_guide/ug_traincascade.html](http://docs.opencv.org/doc/user_guide/ug_traincascade.html).

## Creating <cascade> by running <opencv_traincascade>

Finally, we can generate `<cascade>` by running the following command:

```py

$ <opencv_traincascade> -data <cascade> -vec <binary_description> -bg <negative_description>

```

For other (optional) flags of `<opencv_traincascade>`, see the official documentation at [http://docs.opencv.org/doc/user_guide/ug_traincascade.html](http://docs.opencv.org/doc/user_guide/ug_traincascade.html).

![Note](img/00001.jpg)

### Tip

**Vocalizations**

For good luck, make an imitative sound when running `<opencv_traincascade>`. For example, say "Moo!" if the positive training images are cows.

![Note](img/00001.jpg)

# Testing and improving <cascade>

`<cascade>`是与 OpenCV 的`CascadeClassifier`类的构造函数兼容的 XML 文件。 对于 如何使用`CascadeClassifier`的示例，请参考[第 4 章](4.html#filepos199799 "Chapter 4. Tracking Faces with Haar Cascades")和*用 Haar 级联码*跟踪人脸的`FaceTracker`实现。 。 通过复制和修改`FaceTracker`和`Cameo`，您应该能够创建一个简单的测试应用程序，该应用程序在跟踪的自定义目标实例周围绘制矩形。

也许在您第一次尝试级联训练时，您将不会获得可靠的跟踪结果。 要提高培训效果，请执行以下操作：

*   考虑使分类问题更具体。 例如，`bald, shaven, male face without glasses`级联可能比普通的`face`级联更容易训练。 稍后，随着结果的改善，您可以尝试再次扩大问题范围。
*   收集更多的训练图像，更多！
*   确保`<negative_description>`包含*所有*负面训练图像，仅*包含*负面训练图像。
*   确保`<positive_description>`包含*所有*阳性训练图像，而*仅包含*阳性训练图像。
*   确保`<positive_description>`中指定的子矩形正确。
*   查看并尝试使用`<opencv_createsamples>`和`<opencv_traincascade>`的可选标志。 这些标志在 [http://docs.opencv.org/doc/user_guide/ug_traincascade.html](http://docs.opencv.org/doc/user_guide/ug_traincascade.html) 的官方文档中进行了描述。

祝你好运，寻找图像！

# 摘要

我们已经讨论了用于生成与 OpenCV 的`CascadeClassifier`兼容的级联文件的数据和可执行文件。 现在，您可以开始收集您喜欢的事物的图像并为其训练分类器！