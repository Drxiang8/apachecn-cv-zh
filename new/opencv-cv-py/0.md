# 前言

本书将向您展示如何使用 OpenCV 的 Python 绑定通过普通的网络摄像头或专用的深度传感器（例如 Microsoft Kinect）捕获视频，操纵图像并跟踪对象。 OpenCV 是一个开放源代码，跨平台的库，为计算机视觉实验和应用程序提供了构建基块。 它提供了用于捕获，处理和呈现图像数据的高级界面。 例如，它抽象了有关相机硬件和阵列分配的详细信息。 OpenCV 在学术界和工业界都被广泛使用。

如今，计算机视觉可以通过网络摄像头，照相手机和诸如 Kinect 之类的游戏传感器在许多情况下吸引消费者。 不管是好是坏，人们都喜欢坐在相机上，作为开发人员，我们面临着捕获图像，改变其外观并从中提取信息的应用程序的需求。 OpenCV 的 Python 绑定可以帮助我们以高级语言和可与 NumPy 和 SciPy 等科学库互操作的标准化数据格式探索满足这些要求的解决方案。

尽管 OpenCV 是高级的并且可以互操作，但是对于新用户而言，并不一定很容易。 根据您的需求，OpenCV 的多功能性可能会以复杂的设置过程为代价，并且在如何将可用功能转换为经过组织和优化的应用程序代码方面还存在一些不确定性。 为了帮助您解决这些问题，我努力提供了一本简明的书，重点在于简洁的安装，简洁的应用程序设计以及对每个功能用途的简单理解。 希望您能从本书的项目中学习，扩大规模，并且仍然能够重用我们共同创建的开发环境和部分模块化代码。

特别是，在本书第一章的结尾，您可以拥有一个开发环境，该环境可以链接 Python，OpenCV，深度相机库（OpenNI，SensorKinect）和通用科学库（NumPy，SciPy）。 在五章之后，您可以拥有一个有趣的应用程序的多种变体，该应用程序可以在实时照相机源中操纵用户的脸部。 在此应用程序的后面，您将拥有一个小的可重用函数和类库，您可以在将来的计算机视觉项目中应用它们。 让我们更详细地看书的进展。

# 这本书涵盖的内容

第 1 章，“设置 OpenCV”让我们研究在 Windows，Mac 和 Ubuntu 上设置 Python，OpenCV 和相关库的步骤。 我们还将讨论 OpenCV 的社区，文档和官方代码示例。

第 2 章，“处理文件，相机和 GUI”有助于我们讨论 OpenCV 的 I / O 功能。 然后，使用面向对象的设计，我们编写了一个应用程序，该应用程序显示实时摄像机供稿，处理键盘输入以及编写视频和静态图像文件。

第 3 章，“过滤图像”帮助我们使用 OpenCV，NumPy 和 SciPy 编写图像过滤器。 滤镜效果包括线性颜色操纵，曲线颜色操纵，模糊，锐化和轮廓轮廓。 我们修改了我们的应用程序，以将其中的一些滤镜应用于实时摄像机供稿。

第 4 章，“使用 Haar 级联跟踪脸部”允许我们编写一个分层的脸部跟踪器，该跟踪器使用 OpenCV 定位图像中的脸部，眼睛，鼻子和嘴巴。 我们还编写了用于复制和调整图像区域大小的函数。 我们修改了我们的应用程序，以便它可以找到并处理相机供稿中的人脸。

第 5 章，“检测前景/背景区域和深度”有助于我们了解 OpenCV 可以从深度摄像机捕获的数据类型（在 OpenNI 和 SensorKinect 的支持下）。 然后，我们编写使用此类数据将效果限制到前景区域的函数。 我们将此功能整合到我们的应用程序中，以便我们可以在操作面部区域之前进一步完善它们。

[附录 A](6.html#filepos276737 "Appendix A. Integrating with Pygame") 和*与 Pygame* 集成，让我们修改应用程序以使用 Pygame 代替 OpenCV 来处理某些 I / O 事件。 （Pygame 提供更多种事件处理功能。）

[附录 B](7.html#filepos290879 "Appendix B. Generating Haar Cascades for Custom Targets") ，*为自定义目标生成 Haar 级联*允许我们检查一组 OpenCV 工具，这些工具使我们能够为任何类型的对象或图案（不一定是面孔）构建跟踪器。

# 这本书需要什么

本书提供了所有相关软件的设置说明，包括软件包管理器，构建工具，Python，NumPy，SciPy，OpenCV，OpenNI 和 SensorKinect。 设置说明适用于 Windows XP 或更高版本，Mac OS 10.6（Snow Leopard）或更高版本以及 Ubuntu 12.04 或更高版本。 如果您愿意自己调整设置步骤，则其他类 Unix 的操作系统也应该工作。 您需要针对本书中所述的核心项目使用网络摄像头。 对于其他功能，项目的某些变体使用第二个网络摄像头，甚至使用与 OpenNI 兼容的深度摄像头，例如 Microsoft Kinect 或 Asus Xtion PRO。

# 这本书适合谁

本书非常适合计算机视觉新手并且喜欢通过应用程序开发学习的 Python 开发人员。 假设您以前有使用 Python 和命令行的经验。 对图像数据（例如，像素和颜色通道）的基本了解也将有所帮助。

# 约定

在本书中，您会发现许多可以区分不同类型信息的文本样式。 以下是这些样式的一些示例，并解释了其含义。

文本中的代码字如下所示：“ Windows 上的两个可执行文件称为`ONopencv_createsamples.exe`和`ONopencv_traincascade.exe`。”

代码块设置如下：

```py
negative
    desc.txt
    images
        negative 0.png
        negative 1.png
```

任何命令行输入或输出的编写方式如下：

```py

> cd negative
> forfiles /m images\*.png /c "cmd /c echo @relpath" > desc.txt

```

**新术语**和**重要词**以粗体显示。 您在屏幕上看到的单词，例如在菜单或对话框中，将以如下形式显示在文本中：“单击 **Next** 按钮可将您移至下一个屏幕”。

![Note](img/00001.jpg)

### 注意

警告或重要提示会出现在这样的框中。

![Note](img/00001.jpg)
![Note](img/00001.jpg)

### 提示

提示和技巧如下所示。

![Note](img/00001.jpg)

# 读者反馈

始终欢迎读者的反馈。 让我们知道您对这本书的看法-您喜欢或不喜欢的东西。 读者反馈对于我们开发您真正能充分利用的标题非常重要。

要向我们发送一般性反馈，只需将电子邮件发送到`<[feedback@packtpub.com](mailto:feedback@packtpub.com)>`，然后通过您的邮件主题提及书名。

如果您有专业知识的主题，并且对写作或撰写书籍感兴趣，请参阅[这个页面](http://www.packtpub.com/authors)上的作者指南。

# 客户支持

既然您是 Packt 书的骄傲拥有者，我们可以通过很多方法来帮助您从购买中获得最大收益。

## 下载示例代码

您可以从[这个页面](http://www.packtpub.com)下载从帐户购买的所有 Packt 图书的示例代码文件。 如果您在其他地方购买了此书，则可以访问[这个页面](http://www.packtpub.com/support)并注册以将文件直接通过电子邮件发送给您。 也可以从作者的网站 [http://nummist.com/opencv/](http://nummist.com/opencv/)中获得本书的示例代码。

## 勘误

尽管我们已尽一切努力确保内容的准确性，但还是会发生错误。 如果您发现我们的其中一本书中有错误-可能是文本或代码中的错误-请将此报告给我们，我们将不胜感激。 这样，您可以使其他读者免于沮丧，并帮助我们改进本书的后续版本。 如果您发现任何勘误，请访问[这个页面](http://www.packtpub.com/submit-errata)，选择您的书，然后点击**勘误** **提交[** **表格**链接，然后输入勘误的详细信息。 验证勘误后，您的提交将被接受，并且勘误将上传到我们的网站上，或添加到该标题的“勘误”部分下的任何现有勘误列表中。 通过从[这个页面](http://www.packtpub.com/support)中选择标题，可以查看任何现有的勘误表。

## 盗版

互联网上的版权材料盗版是所有媒体上的一个持续存在的问题。 在 Packt，我们非常重视版权和许可的保护。 如果您在 Internet 上以任何形式发现我们的任何非法作品副本，请立即向我们提供位置地址或网站名称，以便我们寻求补救。

请通过`<[copyright@packtpub.com](mailto:copyright@packtpub.com)>`与我们联系，并提供指向可疑盗版材料的链接。

感谢您在保护我们的作者方面的帮助，以及我们为您带来有价值的内容的能力。

## 问题

如果您对本书的任何方面都有疑问，可以通过`<[questions@packtpub.com](mailto:questions@packtpub.com)>`与我们联系，我们将尽力解决该问题。 您也可以直接通过`<[josephhowse@nummist.com](mailto:josephhowse@nummist.com)>`与作者联系，或者访问其网站 [http://nummist.com/opencv/](http://nummist.com/opencv/) ，以获取有关本书常见问题的答案。